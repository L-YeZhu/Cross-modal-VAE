# Learning Audio-Visual Correlations from Variational Cross-Modal Generations



### 1. We implement the project using
Python 3.6 <br />
Pytorch 1.2

### 2. Please download the audio and visual features from [here](https://github.com/YapengTian/AVE-ECCV18), and place the data files in the data folder. 
To train the model, run the <code>msvae.py</code>. <br />
For the cross-modal localization task, run the <code>cml.py</code>. <br />
For the cross-modal retrieval task, run the <code>retrieval.py</code>. <br />

